{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "723dfaa3-2a53-40e4-a11c-22541f19a11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b493d1-e568-4af9-89fb-13f6fed393b5",
   "metadata": {},
   "source": [
    "### Test MTCNN face detection model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b47ddd3e-26eb-4835-9694-38e51adf5756",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MTCNNFaceNetDetector:\n",
    "    def __init__(self, device='cpu'):\n",
    "        self.device = device\n",
    "        \n",
    "        # Face detector\n",
    "        self.mtcnn = MTCNN(\n",
    "            image_size=160, \n",
    "            margin=0, \n",
    "            min_face_size=20,\n",
    "            device=device,\n",
    "            select_largest=True  # Select largest face if multiple\n",
    "        )\n",
    "        \n",
    "        # Face recognition model (embeddings)\n",
    "        self.resnet = InceptionResnetV1(pretrained='vggface2').eval().to(device)\n",
    "    \n",
    "    def get_embedding(self, image_path):\n",
    "        \"\"\"Extract face embedding from image\"\"\"\n",
    "        img = Image.open(image_path).convert('RGB')\n",
    "        \n",
    "        # Detect and crop face\n",
    "        face = self.mtcnn(img)\n",
    "        \n",
    "        if face is None:\n",
    "            return None\n",
    "        \n",
    "        # Get embedding\n",
    "        with torch.no_grad():\n",
    "            face = face.unsqueeze(0).to(self.device)\n",
    "            embedding = self.resnet(face).cpu().numpy()[0]\n",
    "        \n",
    "        return embedding\n",
    "    \n",
    "    def compare_faces(self, embedding1, embedding2):\n",
    "        \"\"\"Compare two embeddings, return distance\"\"\"\n",
    "        if embedding1 is None or embedding2 is None:\n",
    "            return None\n",
    "        \n",
    "        # Euclidean distance\n",
    "        distance = np.linalg.norm(embedding1 - embedding2)\n",
    "        return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e188e55d-b83c-4d84-8f8a-f0ebdd200e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"/workspaces/face_duplicate_detection/data/images/Aaron Eckhart_1.jpg\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c094422-c955-49d0-94e6-921abd861b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage\n",
    "detector = MTCNNFaceNetDetector()\n",
    "\n",
    "emb1 = detector.get_embedding('person1_photo1.jpg')\n",
    "emb2 = detector.get_embedding('person1_photo2.jpg')\n",
    "\n",
    "if emb1 is not None and emb2 is not None:\n",
    "    distance = detector.compare_faces(emb1, emb2)\n",
    "    print(f\"Distance: {distance:.3f}\")\n",
    "    # Typical threshold: < 0.7 for same person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc79d36-f81b-4fc6-b08f-03f9c19b243e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd24853-cca8-4a64-9667-1581f8dd299e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98923cb3-95bf-465b-a795-4c0c8c8ed749",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6441c16a-0c88-43b8-94cb-5cb951254d4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371119ac-47b5-411b-83eb-218de08bbc71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed59b2e3-2b27-44eb-803e-8307974ad2aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc31483-e5b4-4dcb-b990-35636e4b5d42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45a75d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
